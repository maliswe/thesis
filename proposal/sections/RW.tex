\section{Related Work}
The integration of generative AI into software development has been extensively studied, particularly concerning its impact on productivity, associated security risks, and developer perceptions. This section reviews existing literature in these areas and identifies research gaps that this study aims to address.

\subsection{The Role of Generative AI in Software Development Productivity}
Generative AI tools have significantly impacted software development efficiency by automating routine tasks and providing real-time code suggestions. Studies have shown that developers using AI-assisted coding tools experience notable improvements in productivity. Peng et al. (2023) conducted a controlled experiment revealing that developers using GitHub Copilot completed tasks 55.8\% faster than those without AI assistance \cite{peng2023}. Similarly, a report by McKinsey (2023) highlighted that AI-powered coding assistants reduce debugging time and improve code accuracy, particularly for early-career developers \cite{mckinsey2023}. However, these studies focus primarily on the advantages of AI tools, without addressing their potential risks.


\subsection{Security Risks in AI-Generated Code}
Despite the productivity benefits, AI-generated code introduces security risks that could compromise software integrity. Snyk's 2023 report revealed that over 50\% of organizations faced security vulnerabilities due to AI-generated code, with common issues including weak encryption practices, dependency risks, and hardcoded credentials \cite{snyk2023}. Furthermore, Brown and Williams (2023) analyzed AI model training data and found that public repositories often contain insecure patterns that AI systems reproduce, exacerbating security concerns \cite{ai-training-risks}. While these findings emphasize AI-related security challenges, existing literature lacks a structured framework to mitigate these risks without compromising productivity.

\subsection{Developer Perceptions of AI in Software Development}
Understanding how developers perceive AI-generated code is critical to evaluating its real-world impact. A survey by DevTech Insights (2023) found that while 85\% of developers acknowledged AI’s efficiency gains, only 42\% fully trusted AI-generated code without manual review \cite{devtech2023}. Similarly, recent studies suggest that developers adopt AI assistance differently based on their experience levels, with senior engineers using AI for boilerplate tasks and junior developers relying on it for logic generation \cite{developer-adoption}. These findings indicate that AI trust issues may limit its effectiveness, warranting further investigation.

\subsection{Research Gaps and the Need for Further Study}
Existing studies emphasize either the productivity benefits or security vulnerabilities of AI-generated code but do not adequately examine their trade-offs in a structured manner. Additionally, most research focuses on AI’s effectiveness rather than real-world security implications in production environments. While some frameworks exist for evaluating secure coding practices, they are not tailored to AI-generated code \cite{secure-frameworks2023}. This study aims to bridge these gaps by systematically evaluating the benefits and risks of AI-driven development and proposing actionable recommendations for balancing productivity with security.
