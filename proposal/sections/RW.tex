\section{Related Work}

\subsection{Impact of AI on Developer Productivity}
AI-powered coding assistants have been widely adopted, with studies suggesting significant productivity benefits. Microsoft Research found that developers using GitHub Copilot completed tasks 55.8\% faster than those coding manually \cite{microsoft2023}. IBM’s study on AI pair programming in an enterprise setting observed perceived productivity gains but noted variability based on task complexity and developer experience \cite{ibm2025}. However, Uplevel Data Labs reported conflicting results, stating that Copilot users introduced more defects while their overall task completion rates remained unchanged \cite{uplevel2024}. This discrepancy highlights the need for further investigation into the actual impact of AI coding assistants in real-world scenarios.

\subsection{Security Risks in AI-Generated Code}
Security concerns in AI-generated code have been extensively documented. One of the first empirical evaluations of GitHub Copilot revealed that approximately 40\% of AI-generated code contained vulnerabilities, including SQL injection and buffer overflow issues \cite{fu2023}. Perry et al. found that AI-assisted developers wrote significantly more insecure code than those without AI assistance, despite being more confident in their solutions \cite{perry2023}. Additionally, Asare et al. demonstrated that AI-generated code often replicated past vulnerabilities, repeating the same mistakes found in historical software security incidents \cite{asare2024}. These findings suggest that while AI tools accelerate development, they also introduce new security risks that must be mitigated.

\subsection{Developer Adoption and Perceptions}
Despite security risks, the adoption of AI coding assistants has grown rapidly. A 2023 survey by GitHub reported that over 70\% of developers believed Copilot helped them stay focused and avoid mental fatigue \cite{developer-adoption}. However, Snyk’s industry report found that while 75\% of developers believed AI-generated code was more secure than human-written code, 56\% of respondents admitted to encountering security issues in AI-generated suggestions \cite{snyk2023}. These findings indicate a potential **overconfidence bias** in AI-assisted development, where developers may unknowingly trust insecure AI-generated code.

\subsection{Research Gaps}
While multiple studies have examined AI’s impact on productivity and security, there remains a lack of research that systematically evaluates both aspects together. Most existing studies either focus on productivity gains or security vulnerabilities in isolation. Additionally, prior work has not explored mitigation strategies for balancing efficiency and security when using AI-generated code. This study aims to bridge this gap by evaluating both **productivity and security concerns simultaneously** while identifying best practices for responsible AI-assisted development.
